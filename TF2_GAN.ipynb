{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2 GAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMBauKlj3O2V6UZtEDG3fCb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waltherwj/Tensorflow2-lectures/blob/master/TF2_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6PWD-sdpWRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziiZAh8Ps0mQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense, LeakyReLU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sys, os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA-PoYm1uWMN",
        "colab_type": "code",
        "outputId": "69121900-bfea-49ae-b461-2c3edd7ef243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "#scale data\n",
        "x_train, x_test = (x_train/255.0)*2 - 1, (x_test/255.0)*2 -1\n",
        "print(\"x_train.shape:\", x_train.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train.shape: (60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9y78Tl3vHE4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f357f326-1e3a-419a-ee1f-2be7ea891223"
      },
      "source": [
        "N, H, W, = x_train.shape\n",
        "D = H*W\n",
        "x_train = x_train.reshape(-1,D)   #NOT CONV GAN\n",
        "x_test = x_test.reshape(-1, D)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JuTirQBvlsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hidden dim size\n",
        "hidden_dim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ6NlNVWv6-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the generator model\n",
        "def build_generator(latent_dim):\n",
        "  i = Input(shape=(hidden_dim,))\n",
        "  x = Dense(256, activation=LeakyReLU(alpha=0.2))(i)\n",
        "  x = BatchNormalization(momentum=0.8)(x)\n",
        "  x = Dense(512, activation=LeakyReLU(alpha=0.2))(x)\n",
        "  x = BatchNormalization(momentum=0.8)(x)\n",
        "  x = Dense(D, activation='tanh')(x)\n",
        "\n",
        "  model = Model(i, x)\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac8DZ3pmxMJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the discriminator model\n",
        "def build_discriminator(img_size):\n",
        "  i = Input(shape = (img_size,))\n",
        "  x = Dense(512)(i)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  x = Dense(256)(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "  model = Model(i,x)\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb_ZluL3xZdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#build and compile discriminator\n",
        "discriminator = build_discriminator(D)\n",
        "discriminator.compile(\n",
        "      loss = \"binary_crossentropy\",\n",
        "      optimizer = Adam(learning_rate = 0.0002, beta_1=0.5),\n",
        "      metrics = ['accuracy']\n",
        "                        )\n",
        "\n",
        "#build and compile generator\n",
        "\n",
        "generator = build_generator(hidden_dim)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkGuedod03yd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create noise sample to be fed into generator\n",
        "z = Input(shape=hidden_dim)\n",
        "#for entry in range(z.shape[1]):\n",
        "  #print(z[entry])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwTWaUXW2NaD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "806d798c-867c-4ec7-e655-425a1df39915"
      },
      "source": [
        "# generate image \n",
        "img = generator(z)\n",
        "print(img)\n",
        "\n",
        "# make sure only generator is trainable\n",
        "discriminator.trainable = False\n",
        "\n",
        "# get fake loss\n",
        "fake_pred = discriminator(img)\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"model_1_2/Identity:0\", shape=(None, 784), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fqQhls72sXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create the combined model\n",
        "combined_model = Model(z, fake_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpPtKxY62zYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile combined model\n",
        "combined_model.compile(\n",
        "    loss = 'binary_crossentropy',\n",
        "    optimizer = Adam(0.0002, 0.5)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HP7y_Vb3AnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the GAN\n",
        "\n",
        "#CONFIG\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 30000\n",
        "sample_period = 200 #every sample period steps generate and save some data\n",
        "\n",
        "# create batch labels to use when calling train_on_batch\n",
        "ones = np.ones(batch_size)\n",
        "zeros = np.zeros(batch_size)\n",
        "\n",
        "\n",
        "#store the losses\n",
        "g_losses = []\n",
        "d_losses = []\n",
        "\n",
        "#create a folder to store the generated images\n",
        "if not os.path.exists('gan_images'):\n",
        "  os.makedirs('gan_images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "digBKge_4SKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to save sample images to image file\n",
        "def sample_images(epoch):\n",
        "  rows, cols = 5,5\n",
        "  noise = np.random.randn(rows*cols, hidden_dim)\n",
        "  imgs = generator.predict(noise)\n",
        "\n",
        "  #rescale images 0-1\n",
        "\n",
        "  imgs = 0.5* imgs + 0.5\n",
        "\n",
        "  fig, axs = plt.subplots(rows, cols)\n",
        "  idx = 0\n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      axs[i,j].imshow(imgs[idx].reshape(H,W), cmap = 'gray')\n",
        "      axs[i,j].axis('off')\n",
        "      idx += 1\n",
        "  fig.savefig(\"gan_images/%d.png\" % epoch)\n",
        "  plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6s8KFe_5tjI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "58182aec-b1a2-4eaa-a7e1-c50dbbc27e3d"
      },
      "source": [
        "# Main Training Loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # Discriminator first\n",
        "\n",
        "  # Select random batch of images\n",
        "  idx = np.random.randint(low = 0, high = x_train.shape[0], size = batch_size)\n",
        "  real_imgs = x_train[idx]\n",
        "\n",
        "  #generate fake images\n",
        "  noise = np.random.randn(batch_size, hidden_dim)\n",
        "  fake_imgs = generator.predict(noise)\n",
        "  \n",
        "  #Train the driscriminator\n",
        "  d_loss_real, d_acc_real = discriminator.train_on_batch(real_imgs,ones)\n",
        "  d_loss_fake, d_acc_fake = discriminator.train_on_batch(fake_imgs, zeros)\n",
        "\n",
        "  d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
        "  d_acc = 0.5 * (d_acc_fake + d_acc_real)\n",
        "\n",
        "\n",
        "  #train generator\n",
        "  noise = np.random.randn(batch_size, hidden_dim)\n",
        "  g_loss = combined_model.train_on_batch(noise, ones)\n",
        "  \n",
        "  #save losses\n",
        "\n",
        "  d_losses.append(d_loss)\n",
        "  g_losses.append(g_loss)\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print (f\"epoch: {epoch +1}/{epochs}, d_loss: {d_loss:.2f},\\\n",
        "    d_acc: {d_acc:.2f}, g_loss: {g_loss:.2f}\")\n",
        "\n",
        "  if epoch % sample_period == 0:\n",
        "    sample_images(epoch)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1/30000, d_loss: 0.56,    d_acc: 0.53, g_loss: 0.52\n",
            "epoch: 101/30000, d_loss: 0.01,    d_acc: 1.00, g_loss: 4.75\n",
            "epoch: 201/30000, d_loss: 0.02,    d_acc: 1.00, g_loss: 4.64\n",
            "epoch: 301/30000, d_loss: 0.08,    d_acc: 0.97, g_loss: 4.48\n",
            "epoch: 401/30000, d_loss: 0.34,    d_acc: 0.86, g_loss: 2.14\n",
            "epoch: 501/30000, d_loss: 0.52,    d_acc: 0.72, g_loss: 1.21\n",
            "epoch: 601/30000, d_loss: 0.65,    d_acc: 0.58, g_loss: 0.92\n",
            "epoch: 701/30000, d_loss: 0.59,    d_acc: 0.62, g_loss: 1.04\n",
            "epoch: 801/30000, d_loss: 0.55,    d_acc: 0.75, g_loss: 0.99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztTcUFBl8yXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}